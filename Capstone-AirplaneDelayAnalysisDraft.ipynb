{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7081aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f45f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = pd.read_csv('2009.csv')\n",
    "df_2010 = pd.read_csv('2010.csv')\n",
    "df_2011 = pd.read_csv('2011.csv')\n",
    "df_2012 = pd.read_csv('2012.csv')\n",
    "df_2013 = pd.read_csv('2013.csv')\n",
    "df_2014 = pd.read_csv('2014.csv')\n",
    "df_2015 = pd.read_csv('2015.csv')\n",
    "df_2016 = pd.read_csv('2016.csv')\n",
    "df_2017 = pd.read_csv('2017.csv')\n",
    "df_2018 = pd.read_csv('2018.csv')\n",
    "df_2019 = pd.read_csv('2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e2bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Lists for easier manipulation later on\n",
    "df_list = [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2018, df_2019]\n",
    "df_list_train = [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58b7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df['Delay'] = np.where((df['CARRIER_DELAY'] > 0) | \n",
    "                           (df['WEATHER_DELAY'] > 0) | \n",
    "                           (df['NAS_DELAY'] > 0) | \n",
    "                           (df['SECURITY_DELAY'] > 0) | \n",
    "                           (df['LATE_AIRCRAFT_DELAY'] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab557b",
   "metadata": {},
   "source": [
    "# Exploratory Analysis: \n",
    "Please do not run through this code. The code below analyzes 2009 data to root out Null values and performes cleaning on just 2009 data. Please proceed to the next markdown if you would like to run through this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb182ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.drop(columns=['Unnamed: 27',\n",
    "                 'CRS_DEP_TIME',\n",
    "                 'CANCELLED',\n",
    "                 'CANCELLATION_CODE', \n",
    "                 'DIVERTED', \n",
    "                 'CRS_ELAPSED_TIME', \n",
    "                 'ACTUAL_ELAPSED_TIME',\n",
    "                 'CARRIER_DELAY',\n",
    "                 'WEATHER_DELAY',\n",
    "                 'NAS_DELAY',\n",
    "                 'SECURITY_DELAY', \n",
    "                 'CRS_ARR_TIME',\n",
    "                 'LATE_AIRCRAFT_DELAY'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be154e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_2009.corr()['Delay'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009[df_2009['ARR_TIME'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39352943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbda0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.dropna(subset=['DEP_TIME',\n",
    "                       'DEP_DELAY', \n",
    "                       'TAXI_OUT', \n",
    "                       'WHEELS_OFF', \n",
    "                       'WHEELS_ON', \n",
    "                       'TAXI_IN', \n",
    "                       'ARR_TIME', \n",
    "                       'ARR_DELAY', \n",
    "                       'AIR_TIME'], inplace=True)\n",
    "df_2009.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068eaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "6326976/6429338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8501b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0c56a",
   "metadata": {},
   "source": [
    "**END of Exploratory Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d1e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list_train:\n",
    "    df.drop(columns=['Unnamed: 27',\n",
    "                 'CRS_DEP_TIME',\n",
    "                 'CANCELLED',\n",
    "                 'CANCELLATION_CODE', \n",
    "                 'DIVERTED', \n",
    "                 'CRS_ELAPSED_TIME', \n",
    "                 'ACTUAL_ELAPSED_TIME',\n",
    "                 'CARRIER_DELAY',\n",
    "                 'WEATHER_DELAY',\n",
    "                 'NAS_DELAY',\n",
    "                 'SECURITY_DELAY', \n",
    "                 'CRS_ARR_TIME',\n",
    "                 'LATE_AIRCRAFT_DELAY'], inplace=True)\n",
    "    df.dropna(subset=['DEP_TIME',\n",
    "                       'DEP_DELAY', \n",
    "                       'TAXI_OUT', \n",
    "                       'WHEELS_OFF', \n",
    "                       'WHEELS_ON', \n",
    "                       'TAXI_IN', \n",
    "                       'ARR_TIME', \n",
    "                       'ARR_DELAY', \n",
    "                       'AIR_TIME'], inplace=True)\n",
    "    \n",
    "df_2019.drop(columns=['Unnamed: 20', \n",
    "                 'CARRIER_DELAY',\n",
    "                 'WEATHER_DELAY',\n",
    "                 'NAS_DELAY',\n",
    "                 'SECURITY_DELAY',\n",
    "                 'LATE_AIRCRAFT_DELAY'], inplace=True)\n",
    "df_2019.dropna(subset=['DEP_TIME',\n",
    "                       'DEP_DELAY', \n",
    "                       'TAXI_OUT', \n",
    "                       'WHEELS_OFF', \n",
    "                       'WHEELS_ON', \n",
    "                       'TAXI_IN', \n",
    "                       'ARR_TIME', \n",
    "                       'ARR_DELAY', \n",
    "                       'AIR_TIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5618201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.rename(columns={'OP_UNIQUE_CARRIER':'OP_CARRIER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_size = 4000000\n",
    "\n",
    "# # Iterate through the list of dataframes\n",
    "# for df in df_list_train:\n",
    "#     # Calculate the number of rows to delete\n",
    "#     rows_to_delete = df.shape[0] - target_size\n",
    "#     # Create a list of row indices to delete\n",
    "#     rows_to_delete = random.sample(range(df.shape[0]), rows_to_delete)\n",
    "#     # Delete the rows from the dataframe\n",
    "#     df.drop(rows_to_delete, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f31b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a40296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list = df_train['OP_CARRIER'].isin(['AA', 'B6', 'WN', 'DL', 'F9', 'AS', 'NK', 'UA', '9E', 'CO', 'FL', 'HA'])\n",
    "df_train = df_train[in_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list_1 = df_2019['OP_CARRIER'].isin(['AA', 'B6', 'WN', 'DL', 'F9', 'AS', 'NK', 'UA', '9E', 'CO', 'FL', 'HA'])\n",
    "df_test = df_2019[in_list_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_size = 30000000\n",
    "\n",
    "# # Calculate the number of rows to delete\n",
    "# rows_to_delete = df_train.shape[0] - target_size\n",
    "# # Create a list of row indices to delete\n",
    "# rows_to_delete = random.sample(range(df_train.shape[0]), rows_to_delete)\n",
    "# # Delete the rows from the dataframe\n",
    "# df_train.drop(rows_to_delete, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c13155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['FL_DATE'])\n",
    "\n",
    "# Extract the year, month, and day of the week from the date field\n",
    "df_train['year'] = df_train['date'].dt.year\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_train['day_of_week'] = df_train['date'].dt.dayofweek\n",
    "\n",
    "# Drop the original date field\n",
    "df_train = df_train.drop(columns=['date', 'FL_DATE'])\n",
    "df_train= df_train[['year', 'month', 'day_of_week', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
    "                               'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'ARR_TIME',\n",
    "                               'ARR_DELAY', 'AIR_TIME', 'DISTANCE', 'Delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae28669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset=['year', 'month', 'day_of_week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f443d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162a222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reboyce\\AppData\\Local\\Temp\\ipykernel_20884\\1480642278.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['date'] = pd.to_datetime(df_test['FL_DATE'])\n",
      "C:\\Users\\reboyce\\AppData\\Local\\Temp\\ipykernel_20884\\1480642278.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['year'] = df_test['date'].dt.year\n",
      "C:\\Users\\reboyce\\AppData\\Local\\Temp\\ipykernel_20884\\1480642278.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['month'] = df_test['date'].dt.month\n",
      "C:\\Users\\reboyce\\AppData\\Local\\Temp\\ipykernel_20884\\1480642278.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['day_of_week'] = df_test['date'].dt.dayofweek\n"
     ]
    }
   ],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test['FL_DATE'])\n",
    "\n",
    "# Extract the year, month, and day of the week from the date field\n",
    "df_test['year'] = df_test['date'].dt.year\n",
    "df_test['month'] = df_test['date'].dt.month\n",
    "df_test['day_of_week'] = df_test['date'].dt.dayofweek\n",
    "\n",
    "# Drop the original date field\n",
    "df_test = df_test.drop(columns=['date', 'FL_DATE'])\n",
    "df_test = df_test[['year', 'month', 'day_of_week', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
    "                               'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'ARR_TIME',\n",
    "                               'ARR_DELAY', 'AIR_TIME', 'DISTANCE', 'Delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81b3e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset=['year', 'month', 'day_of_week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37773708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>1</td>\n",
       "      <td>ORD</td>\n",
       "      <td>HNL</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>4244.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>2</td>\n",
       "      <td>HNL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>4244.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>2</td>\n",
       "      <td>ORD</td>\n",
       "      <td>CLT</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>5</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SFO</td>\n",
       "      <td>603.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>2586.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>7</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SFO</td>\n",
       "      <td>711.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2586.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  day_of_week OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "3102  2009      1            3         UA                  1    ORD  HNL   \n",
       "3103  2009      1            3         UA                  2    HNL  ORD   \n",
       "3104  2009      1            3         UA                  2    ORD  CLT   \n",
       "3105  2009      1            3         UA                  5    JFK  SFO   \n",
       "3106  2009      1            3         UA                  7    JFK  SFO   \n",
       "\n",
       "      DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  WHEELS_ON  TAXI_IN  ARR_TIME  \\\n",
       "3102    1013.0       -1.0      14.0      1027.0     1456.0      2.0    1458.0   \n",
       "3103    1737.0       12.0      14.0      1751.0      510.0      6.0     516.0   \n",
       "3104     630.0        0.0      13.0       643.0      858.0      5.0     903.0   \n",
       "3105     603.0       -2.0      30.0       633.0      942.0      4.0     946.0   \n",
       "3106     711.0        3.0      24.0       735.0     1057.0      7.0    1104.0   \n",
       "\n",
       "      ARR_DELAY  AIR_TIME  DISTANCE  Delay  \n",
       "3102      -28.0     509.0    4244.0      0  \n",
       "3103       -7.0     439.0    4244.0      0  \n",
       "3104      -14.0      75.0     599.0      0  \n",
       "3105        5.0     369.0    2586.0      0  \n",
       "3106        4.0     382.0    2586.0      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078f7781",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_rng\n\u001b[0;32m      3\u001b[0m arr_indices_top_drop \u001b[38;5;241m=\u001b[39m default_rng()\u001b[38;5;241m.\u001b[39mchoice(df_train\u001b[38;5;241m.\u001b[39mindex, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000000\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marr_indices_top_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4338\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4336\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39maxis\u001b[38;5;241m.\u001b[39misin(labels)\n\u001b[0;32m   4337\u001b[0m \u001b[38;5;66;03m# Check if label doesn't exist along axis\u001b[39;00m\n\u001b[1;32m-> 4338\u001b[0m labels_missing \u001b[38;5;241m=\u001b[39m (\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m   4339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m labels_missing:\n\u001b[0;32m   4340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5765\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m   5764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer(target)\n\u001b[1;32m-> 5765\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5741\u001b[0m, in \u001b[0;36mIndex.get_indexer_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5736\u001b[0m     \u001b[38;5;66;03m# error: \"IndexEngine\" has no attribute \"_extract_level_codes\"\u001b[39;00m\n\u001b[0;32m   5737\u001b[0m     tgt_values \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39m_extract_level_codes(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   5738\u001b[0m         target\n\u001b[0;32m   5739\u001b[0m     )\n\u001b[1;32m-> 5741\u001b[0m indexer, missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer), ensure_platform_int(missing)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:424\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<__array_function__ internals>:4\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "arr_indices_top_drop = default_rng().choice(df_train.index, size=20000000, replace=False)\n",
    "df_train.drop(index=arr_indices_top_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_size = 20000000\n",
    "\n",
    "# # Calculate the number of rows to delete\n",
    "# rows_to_delete = df_train.shape[0] - target_size\n",
    "# # Create a list of row indices to delete\n",
    "# rows_to_delete = random.sample(range(df_train.shape[0]), rows_to_delete)\n",
    "# # Delete the rows from the dataframe\n",
    "# df_train.drop(rows_to_delete, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['OP_CARRIER', 'ORIGIN', 'DEST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a5ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.get_dummies(df_test, columns=['OP_CARRIER', 'ORIGIN', 'DEST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b48c20",
   "metadata": {},
   "source": [
    "# Graph Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9058e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_counts = df_train.groupby('OP_CARRIER')['Delay'].size()\n",
    "\n",
    "print(delay_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0898c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = delay_counts.index\n",
    "y_values = delay_counts.values \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x_values, y_values)\n",
    "\n",
    "ax.set_title('Delay Counts by Airline from 2009-2018')\n",
    "ax.set_xlabel('Airline')\n",
    "ax.set_ylabel('Delay Count')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ea3ab",
   "metadata": {},
   "source": [
    "**End of Graph Stuff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668818c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='Delay')\n",
    "y_train = df_train['Delay']\n",
    "X_test = df_test.drop(columns='Delay')\n",
    "y_test = df_test['Delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# # Make predictions on new data\n",
    "# new_data = [[...], [...], ...]  # input features for the new data\n",
    "# predictions = model.predict(new_data)\n",
    "# print('Predictions:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0f832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
